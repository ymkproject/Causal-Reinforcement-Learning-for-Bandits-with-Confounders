# Causal Reinforcement Learning for Bandits Implementation

π“ λ³Έ μ €μ¥μ†λ” λ…Όλ¬Έ "Causal Reinforcement Learning for Bandits with Unobserved Confounders" (Mingwei Deng, 2023)μ μ•κ³ λ¦¬μ¦μ„ PythonμΌλ΅ μ§μ ‘ κµ¬ν„ν•κ³  μ¬ν„ν• ν”„λ΅μ νΈμ…λ‹λ‹¤.

λ‹¨μ μ¬ν„μ„ λ„μ–΄, λ…Όλ¬Έμ—μ„ κ³ λ ¤ν•μ§€ μ•μ€ μƒλ΅μ΄ ν™κ²½ λ³€μ(κµλ€ κ°•λ„ $\alpha$, λΉ„μ„ ν•μ„± $\lambda$)**λ¥Ό μ¶”κ°€ν•μ—¬ μ•κ³ λ¦¬μ¦μ κ°•κ±΄μ„±(Robustness)μ„ κ²€μ¦ν•λ” ν™•μ¥ μ‹¤ν— μ½”λ“λ¥Ό ν¬ν•¨ν•κ³  μμµλ‹λ‹¤.

---

### π“‚ μ£Όμ” κΈ°λ¥ λ° μ•κ³ λ¦¬μ¦

1.  μ•κ³ λ¦¬μ¦ 1: Binary Causal Bandit
    * μ΄μ§„ λ³€μ ν™κ²½($Z, X, Y \in \{0, 1\}$)μ—μ„μ μΈκ³Ό λ°΄λ”§ μ•κ³ λ¦¬μ¦ κµ¬ν„.
    * `CausalAgent`, `CUCBAgent`, `CTSAgent` μ„±λ¥ λΉ„κµ.
    * [ν™•μ¥ κΈ°λ¥] κµλ€ κ°•λ„ νλΌλ―Έν„° `alpha_conf` μ¶”κ°€: μ†μ¤/νƒ€κ² λ„λ©”μΈ κ°„μ μΈκ³Ό κµ¬μ΅° μ„ΈκΈ° μ°¨μ΄λ¥Ό μ‹λ®¬λ μ΄μ….

2.  μ•κ³ λ¦¬μ¦ 2: Continuous (VAE) Causal Bandit
    * μ—°μ†ν• λ³€μ λ° κ³ μ°¨μ› ν”„λ΅μ‹ ν™κ²½μ—μ„μ VAE κΈ°λ° μΈκ³Ό λ°΄λ”§ κµ¬ν„.
    * `CausalVAEAgent` (Encoder-Decoder κµ¬μ΅°) vs `LinUCBAgent` μ„±λ¥ λΉ„κµ.
    * **[ν™•μ¥ κΈ°λ¥]** λΉ„μ„ ν• κ°•λ„ νλΌλ―Έν„° `NONLINEAR_STRENGTH` μ¶”κ°€: λ°μ΄ν„° μƒμ„± κ³Όμ •μ— λΉ„μ„ ν• ν•­($\sin(Z)$)μ„ μ£Όμ…ν•μ—¬ λ¨λΈ λ¶μΌμΉ(Model Mismatch) ν™κ²½ ν…μ¤νΈ.

---

### π€ μ‹¤ν–‰ λ°©λ²• (Usage)

#### 1. ν•„μ λΌμ΄λΈλ¬λ¦¬ μ„¤μΉ
λ³Έ μ½”λ“λ” `tensorflow`, `numpy`, `matplotlib`, `scipy` λ“±μ„ μ‚¬μ©ν•©λ‹λ‹¤. ν•κΈ€ ν°νΈ μ§€μ›μ„ μ„ν•΄ `koreanize-matplotlib`λ„ ν•„μ”ν•©λ‹λ‹¤.

```bash
pip install tensorflow numpy matplotlib scipy koreanize-matplotlib
